{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gyJJIOnn8AHJ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/AIGCDetectBenchmark/blob/main/colab/PIE_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition\n",
        "https://github.com/Morpheus3000/PIE-Net/tree/main?tab=readme-ov-file  \n"
      ],
      "metadata": {
        "id": "OTiypmgfnX4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcptCr5laHp",
        "outputId": "81d203e7-a4c3-4702-91b0-366b7fa8d808"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Morpheus3000/PIE-Net.git"
      ],
      "metadata": {
        "id": "5ZPlyYRzAVAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e053ad5-020a-47d7-bb17-676f26843464"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PIE-Net'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 61 (delta 13), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Receiving objects: 100% (61/61), 30.81 MiB | 22.17 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "VfkfgrKKnPzo"
      },
      "outputs": [],
      "source": [
        "#!wget https://uvaauas.figshare.com/ndownloader/files/35467808\n",
        "!cp /content/drive/MyDrive/WEIGHTS/PIE-Net/real_world_model.t7 /content/PIE-Net/model/real_world_model.t7"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/drive/MyDrive/DATASETS/RealFakeDB512/RealFakeDB512s.zip -d /content/PIE-Net/RealFakeDB512s"
      ],
      "metadata": {
        "id": "lLOsv-GW4uBi"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PIE-Net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaSfvfRR5mbO",
        "outputId": "45ac1e28-671f-492d-bf79-92ccc3b017b3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PIE-Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dset = 'RealFakeDB512s/train/0_real'\n",
        "!python Eval.py --data_root $dset --out_puts results/PIE/$dset"
      ],
      "metadata": {
        "id": "ZtC6YGg6pEAd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -q -r /content/RealFakeDB512s_train.zip /content/PIE-Net/RealFakeDB512s/train"
      ],
      "metadata": {
        "id": "etr_h1DqDblh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/RealFakeDB512s_train.zip /content/drive/MyDrive/DATASETS/RealFakeDB512"
      ],
      "metadata": {
        "id": "MjiG2BoUD5kS"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit rpogram\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import imageio\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from Network import DecScaleClampedIllumEdgeGuidedNetworkBatchNorm\n",
        "from Utils import mor_utils\n",
        "\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Tạo một đối tượng ArgumentParser\n",
        "parser = argparse.ArgumentParser(description='PIE_Net')\n",
        "\n",
        "# Thêm đối số với tên gợi ý\n",
        "parser.add_argument('--data_root', type=str, help='Description of arg1')\n",
        "parser.add_argument('--out_puts', type=str, help='Description of arg2')\n",
        "\n",
        "# Parse các đối số từ dòng lệnh\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "cudaDevice = ''\n",
        "\n",
        "if len(cudaDevice) < 1:\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print('[*] GPU Device selected as default execution device.')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print('[X] WARN: No GPU Devices found on the system! Using the CPU. '\n",
        "              'Execution maybe slow!')\n",
        "else:\n",
        "    device = torch.device('cuda:%s' % cudaDevice)\n",
        "    print('[*] GPU Device %s selected as default execution device.' %\n",
        "          cudaDevice)\n",
        "\n",
        "#visuals = 'test_outputs/'\n",
        "visuals = args.out_puts\n",
        "\n",
        "os.makedirs(visuals, exist_ok=True)\n",
        "\n",
        "modelSaveLoc = 'model/real_world_model.t7'\n",
        "\n",
        "#data_root = 'test'\n",
        "query_fmt = 'jpg'\n",
        "\n",
        "# Truy cập các đối số trong mã Python\n",
        "data_root = args.data_root\n",
        "\n",
        "batch_size = 1\n",
        "nthreads = 4\n",
        "if batch_size < nthreads:\n",
        "    nthreads = batch_size\n",
        "\n",
        "done = u'\\u2713'\n",
        "\n",
        "print('[I] STATUS: Create utils instances...', end='')\n",
        "support = mor_utils(device)\n",
        "print(done)\n",
        "\n",
        "print('[I] STATUS: Load Network and transfer to device...', end='')\n",
        "net = DecScaleClampedIllumEdgeGuidedNetworkBatchNorm().to(device)\n",
        "net, _, _ = support.loadModels(net, modelSaveLoc)\n",
        "net.to(device)\n",
        "print(done)\n",
        "\n",
        "def readFile(name):\n",
        "    im = imageio.imread(name)\n",
        "    if len(im.shape) == 2:  # Kiểm tra xem ảnh có 2 chiều không (ảnh xám)\n",
        "      im = np.stack((im,) * 3, axis=-1)  # Lặp lại giá trị pixel 3 lần\n",
        "    rgb = im.astype(np.float32)\n",
        "    rgb[np.isnan(rgb)] = 0\n",
        "    rgb = cv2.resize(rgb, (256, 256))\n",
        "    rgb = rgb / 255\n",
        "\n",
        "    rgb = rgb.transpose((2, 0, 1))\n",
        "    return rgb\n",
        "\n",
        "def Eval(net):\n",
        "    net.eval()\n",
        "    #print(os.listdir(data_root))\n",
        "    #files = glob.glob(data_root + '*.%s' % query_fmt)\n",
        "    files = os.listdir(data_root)\n",
        "    print('Found %d files at query location' % len(files))\n",
        "    #files = ['/content/PIE-Net/test/000609798.jpg']\n",
        "    i = 0\n",
        "    for data in tqdm(files):\n",
        "        if i<0:\n",
        "          break\n",
        "        i+=1\n",
        "        #data = data.split('/')[-1]\n",
        "        \n",
        "        img = readFile(os.path.join(data_root,data))\n",
        "        rgb = Variable(torch.from_numpy(img).float()).to(device)\n",
        "        rgb = rgb.unsqueeze(0)\n",
        "        [b, c, w, h] = rgb.shape\n",
        "\n",
        "        net_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            pred = net(rgb)\n",
        "\n",
        "        net_timed = time.time() - net_time\n",
        "\n",
        "        for j in range(b):\n",
        "            pred_dict = {'reflectance': pred['reflectance'][j, :, :, :],\n",
        "                         #'img': rgb[j, :, :, :],\n",
        "                         'shading': pred['shading'][j, :, :, :],\n",
        "                        }\n",
        "            support.dumpOutputs3(visuals, pred_dict, filename=data, Train=False)\n",
        "\n",
        "\n",
        "print('[*] Beginning Testing:')\n",
        "print('\\tVisuals Dumped at: ', visuals)\n",
        "\n",
        "Eval(net)\n"
      ],
      "metadata": {
        "id": "-8b8dy_37lTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit Ultils  \n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class mor_utils:\n",
        "\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "\n",
        "    def printTensorList(self, data):\n",
        "        if isinstance(data, dict):\n",
        "            print('Dictionary Containing: ')\n",
        "            print('{')\n",
        "            for key, tensor in data.items():\n",
        "                print('\\t', key, end='')\n",
        "                print(' with Tensor of Size: ', tensor.size())\n",
        "            print('}')\n",
        "        else:\n",
        "            print('List Containing: ')\n",
        "            print('[')\n",
        "            for tensor in data:\n",
        "                print('\\tTensor of Size: ', tensor.size())\n",
        "            print(']')\n",
        "\n",
        "    def saveModels(self, model, optims, iterations, path):\n",
        "        if isinstance(model, nn.DataParallel):\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.module.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        else:\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    def loadModels(self, model, path, optims=None, Test=True):\n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "        if not Test:\n",
        "            optims.load_state_dict(checkpoint['optimizer'])\n",
        "        return model, optims, checkpoint['iters']\n",
        "\n",
        "    def dumpOutputs(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            imageio.imwrite((vis + '/%s_pred_alb.png') % filename, pred_a)\n",
        "            imageio.imwrite((vis + '/%s_pred_shd.png') % filename, pred_s)\n",
        "\n",
        "    def dumpOutputs3(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            for k, ele in preds.items():\n",
        "                pred = ele.cpu().detach().clone().numpy()\n",
        "                pred[pred < 0] = 0\n",
        "                pred = (pred / pred.max()) * 255\n",
        "                pred = pred.transpose((1, 2, 0))\n",
        "                pred = pred.astype(np.uint8)\n",
        "                #print('shape is === ', pred.shape)\n",
        "                #pred = Image.fromarray(pred)\n",
        "                #pred = pred.convert(\"RGB\")\n",
        "                if (pred.shape==(256,256,1)):\n",
        "                  #print(pred.shape)\n",
        "                  pred = pred.squeeze()\n",
        "                  #print(pred.shape)\n",
        "                imageio.imwrite((vis + '/%s_%s.jpg') % (filename, k), pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gyJJIOnn8AHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZs5GdsK76pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import imageio\n",
        "import numpy as np\n",
        "im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n",
        "print(im.shape)\n",
        "if len(im.shape) == 2:  # Kiểm tra xem ảnh có 2 chiều không (ảnh xám)\n",
        "    im = np.stack((im,) * 3, axis=-1)  # Lặp lại giá trị pixel 3 lần\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxE220w-z0GR",
        "outputId": "9b0a5c05-bcbd-46a9-a2f8-92c4e96bc095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-d8a6d4c270f7>:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(im.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ko0yLOFz-AG",
        "outputId": "6cc20db0-1827-46ac-a94d-141da22aaa74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n"
          ]
        }
      ]
    }
  ]
}