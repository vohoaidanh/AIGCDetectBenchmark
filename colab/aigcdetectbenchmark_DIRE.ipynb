{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "aigcdetectbenchmark_DIRE.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/AIGCDetectBenchmark/blob/main/colab/aigcdetectbenchmark_DIRE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AIGCDetectBenchmark\n"
      ],
      "metadata": {
        "id": "4bsPZQKgE3tX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AR7UgjyUfRcg",
        "outputId": "58de77c1-b2e9-457e-fad0-fb00ba7532f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4Tiyb4jExor",
        "outputId": "bc7fb695-c616-4075-e723-cb3492283bd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AIGCDetectBenchmark'...\n",
            "remote: Enumerating objects: 660, done.\u001b[K\n",
            "remote: Counting objects: 100% (660/660), done.\u001b[K\n",
            "remote: Compressing objects: 100% (474/474), done.\u001b[K\n",
            "remote: Total 660 (delta 287), reused 507 (delta 166), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (660/660), 7.19 MiB | 20.87 MiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/vohoaidanh/AIGCDetectBenchmark.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy\n",
        "!pip install natsort\n",
        "!pip install tensorboardX\n",
        "!pip install blobfile\n",
        "!pip install mpi4py\n",
        "!pip install comet_ml"
      ],
      "metadata": {
        "id": "_RxwPy40aDO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/AIGCDetectBenchmark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9HXSjhchADX",
        "outputId": "e7a96859-34e6-4b9b-ae14-2c9af8da7b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AIGCDetectBenchmark\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_in_drive = ''\n",
        "dataset_dir = '/content/drive/MyDrive/DATASETS/DIRE/DiffusionForensics'\n",
        "checkpoint = '/content/drive/MyDrive/WEIGHTS/Intrinsic_detector'\n",
        "\n",
        "#import shutil\n",
        "#shutil.copytree(data_in_drive, dataset_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "xalX3dMAbvnv",
        "outputId": "60c2e564-9d8b-48d5-fff3-bbcba476eba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/AIGCDetectBenchmark/dataset'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --name test_with_DIRE_reconstruct \\\n",
        "--dataroot $dataset_dir \\\n",
        "--checkpoints_dir $checkpoint \\\n",
        "--detect_method CNNSpot --blur_prob 0.1 --blur_sig 0.0,3.0 --jpg_prob 0.1 --jpg_method cv2,pil --jpg_qual 30,100"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pE6ypWCQJ92g",
        "outputId": "8b34aac9-52f1-4673-af83-0c37470ff7f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Valid Comet API Key saved in /root/.comet.config (set COMET_CONFIG to change where it is saved).\n",
            "----------------- Options ---------------\n",
            "                 CropSize: 224                           \n",
            "               batch_size: 64                            \n",
            "                    beta1: 0.9                           \n",
            "                blur_prob: 0.1                           \n",
            "                 blur_sig: 0.0,3.0                       \n",
            "          checkpoints_dir: /content/drive/MyDrive/WEIGHTS/Intrinsic_detector\t[default: ./checkpoints]\n",
            "                  classes: ['airplane', 'bird', 'bicycle', 'boat', 'bottle', 'bus', 'car', 'cat', 'cow', 'chair', 'diningtable', 'dog', 'person', 'pottedplant', 'motorbike', 'tvmonitor', 'train', 'sheep', 'sofa', 'horse']\t[default: airplane,bird,bicycle,boat,bottle,bus,car,cat,cow,chair,diningtable,dog,person,pottedplant,motorbike,tvmonitor,train,sheep,sofa,horse]\n",
            "           continue_train: False                         \n",
            "                 data_aug: False                         \n",
            "                 dataroot: /content/drive/MyDrive/DATASETS/DIRE/DiffusionForensics\t[default: /hotdata/share/AIGCDetect]\n",
            "            detect_method: CNNSpot                       \n",
            "          earlystop_epoch: 5                             \n",
            "              epoch_count: 1                             \n",
            "             fix_backbone: False                         \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                    isVal: False                         \t[default: None]\n",
            "               jpg_method: cv2,pil                       \n",
            "                 jpg_prob: 0.1                           \n",
            "                 jpg_qual: 30,100                        \n",
            "               last_epoch: -1                            \n",
            "                 loadSize: 256                           \n",
            "                loss_freq: 400                           \n",
            "                       lr: 0.0001                        \n",
            "                     mode: binary                        \n",
            "                     name: test_with_DIRE_reconstruct    \t[default: experiment_name]\n",
            "                new_optim: False                         \n",
            "                    niter: 1000                          \n",
            "                  no_crop: False                         \n",
            "                  no_flip: False                         \n",
            "                no_resize: False                         \n",
            "                    optim: adam                          \n",
            "              results_dir: ./results/CNNSpot             \t[default: None]\n",
            "                rz_interp: bilinear                      \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 2000                          \n",
            "              train_split: train                         \n",
            "                val_split: val                           \n",
            "             weight_decay: 0.0                           \n",
            "----------------- End -------------------\n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m To get all data logged automatically, import comet_ml before the following modules: torch.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com \u001b[38;5;39mhttps://www.comet.com/danhvohoai2-gmail-com/ai-generated-image-detection/a9f58aa5bf7c44d8bb1b3520b5ff1def\u001b[0m\n",
            "\n",
            "#training images = 56\n",
            "saving the model at the end of epoch 0, iters 56\n",
            "(Val @ epoch 0) acc: 0.8337053571428571; ap: 0.9329291588363744\n",
            "Validation accuracy increased (-inf --> 0.833705).  Saving model ...\n",
            "(Val @ epoch 1) acc: 0.8549107142857143; ap: 0.9459404134719578\n",
            "Validation accuracy increased (0.833705 --> 0.854911).  Saving model ...\n",
            "(Val @ epoch 2) acc: 0.8727678571428571; ap: 0.9550656331081605\n",
            "Validation accuracy increased (0.854911 --> 0.872768).  Saving model ...\n",
            "(Val @ epoch 3) acc: 0.8939732142857143; ap: 0.9525310458049272\n",
            "Validation accuracy increased (0.872768 --> 0.893973).  Saving model ...\n",
            "(Val @ epoch 4) acc: 0.8783482142857143; ap: 0.9463883857197646\n",
            "EarlyStopping counter: 1 out of 5\n",
            "saving the model at the end of epoch 5, iters 336\n",
            "(Val @ epoch 5) acc: 0.8649553571428571; ap: 0.943399265915521\n",
            "EarlyStopping counter: 2 out of 5\n",
            "(Val @ epoch 6) acc: 0.796875; ap: 0.9522622354789028\n",
            "EarlyStopping counter: 3 out of 5\n",
            "Train loss: 0.054578959941864014 at step: 400\n",
            "(Val @ epoch 7) acc: 0.8705357142857143; ap: 0.9525487403218523\n",
            "EarlyStopping counter: 4 out of 5\n",
            "(Val @ epoch 8) acc: 0.875; ap: 0.9551806318462851\n",
            "EarlyStopping counter: 5 out of 5\n",
            "Learning rate dropped by 10, continue training...\n",
            "(Val @ epoch 9) acc: 0.90625; ap: 0.9633697015301421\n",
            "Validation accuracy increased (-inf --> 0.906250).  Saving model ...\n",
            "saving the model at the end of epoch 10, iters 616\n",
            "(Val @ epoch 10) acc: 0.9107142857142857; ap: 0.9665480057271892\n",
            "Validation accuracy increased (0.906250 --> 0.910714).  Saving model ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python eval_all.py --detect_method intrinsic --model_path /content/AIGCDetectBenchmark/checkpoints/model_epoch_best.pth"
      ],
      "metadata": {
        "id": "19VIBcPsI5lX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}