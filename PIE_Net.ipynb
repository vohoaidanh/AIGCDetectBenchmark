{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gyJJIOnn8AHJ"
      ],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/AIGCDetectBenchmark/blob/main/PIE_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition\n",
        "https://github.com/Morpheus3000/PIE-Net/tree/main?tab=readme-ov-file  \n"
      ],
      "metadata": {
        "id": "OTiypmgfnX4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcptCr5laHp",
        "outputId": "23f8b647-47fe-4889-deff-827e6a371041"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Morpheus3000/PIE-Net.git"
      ],
      "metadata": {
        "id": "5ZPlyYRzAVAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08925382-bb08-403e-f37a-44d8d8bdf57c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PIE-Net'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 61 (delta 13), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Receiving objects: 100% (61/61), 30.81 MiB | 24.63 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkfgrKKnPzo",
        "outputId": "a4d8532e-aba6-4870-aca7-621169c40e2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-28 10:35:35--  https://uvaauas.figshare.com/ndownloader/files/35467808\n",
            "Resolving uvaauas.figshare.com (uvaauas.figshare.com)... 34.249.22.33, 52.30.40.166, 2a05:d018:1f4:d000:b899:c458:6346:b0d3, ...\n",
            "Connecting to uvaauas.figshare.com (uvaauas.figshare.com)|34.249.22.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T103535Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2f08b03b27530d87ffb2faa4c275d2a2c1e7a669968132ee1126507f3a1a79a8 [following]\n",
            "--2024-02-28 10:35:35--  https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T103535Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=2f08b03b27530d87ffb2faa4c275d2a2c1e7a669968132ee1126507f3a1a79a8\n",
            "Resolving s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)... 163.172.208.8, 2001:bc8:1401::8\n",
            "Connecting to s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)|163.172.208.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2449443791 (2.3G) [application/octet-stream]\n",
            "Saving to: ‘35467808’\n",
            "\n",
            "35467808            100%[===================>]   2.28G  29.6MB/s    in 82s     \n",
            "\n",
            "2024-02-28 10:36:58 (28.6 MB/s) - ‘35467808’ saved [2449443791/2449443791]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://uvaauas.figshare.com/ndownloader/files/35467808\n",
        "#!cp /content/drive/MyDrive/WEIGHTS/PIE-Net/real_world_model.t7 /content/PIE-Net/model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PIE-Net"
      ],
      "metadata": {
        "id": "kz7QKPIhpBHh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python Eval.py --data_root RealFakeDB_tiny/test/1_fake --out_puts data/PIE_Net_RealFakeDB_tiny/test/1_fake"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtC6YGg6pEAd",
        "outputId": "d69949bf-98f5-4194-9cf8-a8a4ed26ea2c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] GPU Device selected as default execution device.\n",
            "[I] STATUS: Create utils instances...✓\n",
            "[I] STATUS: Load Network and transfer to device...✓\n",
            "[*] Beginning Testing:\n",
            "\tVisuals Dumped at:  data/PIE_Net_RealFakeDB_tiny/test/1_fake\n",
            "Found 1000 files at query location\n",
            "  0% 0/1000 [00:00<?, ?it/s]/content/PIE-Net/Eval.py:82: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread(name)\n",
            " 59% 591/1000 [03:21<02:19,  2.93it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python Eval.py --data_root RealFakeDB_tiny/train/0_real --out_puts data/PIE_Net_RealFakeDB_tiny/train/0_real\n",
        "!python Eval.py --data_root RealFakeDB_tiny/train/1_fake --out_puts data/PIE_Net_RealFakeDB_tiny/train/1_fake"
      ],
      "metadata": {
        "id": "Ht2DTFBzZBWH",
        "outputId": "692b3592-1251-402a-b8e2-1d3861dc9255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] GPU Device selected as default execution device.\n",
            "[I] STATUS: Create utils instances...✓\n",
            "[I] STATUS: Load Network and transfer to device...✓\n",
            "[*] Beginning Testing:\n",
            "\tVisuals Dumped at:  data/PIE_Net_RealFakeDB_tiny/train/1_fake\n",
            "Found 964 files at query location\n",
            "  0% 0/964 [00:00<?, ?it/s]/content/PIE-Net/Eval.py:82: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread(name)\n",
            "100% 964/964 [05:12<00:00,  3.09it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/PIE-Net/test')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOO-nyUumaXh",
        "outputId": "f16a6dc6-1b1d-44c7-d0fb-42743e6c918c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo thư mục mới\n",
        "\"\"\"\n",
        "!mkdir -p /content/PIE-Net/data/PIE_Net_RealFakeDB_tiny/test/0_real/\n",
        "!mkdir -p /content/PIE-Net/data/PIE_Net_RealFakeDB_tiny/test/1_fake/\n",
        "!mkdir -p /content/PIE-Net/data/PIE_Net_RealFakeDB_tiny/train/0_real/\n",
        "!mkdir -p /content/PIE-Net/data/PIE_Net_RealFakeDB_tiny/train/1_fake/\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "o9r68U_DsCl0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/PIE-Net/model/real_world_model.t7 /content/drive/MyDrive/WEIGHTS/PIE-Net\n",
        "#!cp /content/drive/MyDrive/DATASETS/real_gen_dataset.zip /content/"
      ],
      "metadata": {
        "id": "WkuTBfJ3_VnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/drive/MyDrive/DATASETS/RealFakeDB_tiny.zip -d /content/PIE-Net/\n",
        "!zip -r PIE_Net_RealFakeDB_tiny.zip data/PIE_Net_RealFakeDB_tiny\n",
        "#!cp PIE_Net_real_gen_dataset.zip /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "wN8JoNYrrdL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp PIE_Net_RealFakeDB_tiny.zip /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "Y_KQaWKDaKpO"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit rpogram\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import imageio\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from Network import DecScaleClampedIllumEdgeGuidedNetworkBatchNorm\n",
        "from Utils import mor_utils\n",
        "\n",
        "\n",
        "import argparse\n",
        "\n",
        "# Tạo một đối tượng ArgumentParser\n",
        "parser = argparse.ArgumentParser(description='PIE_Net')\n",
        "\n",
        "# Thêm đối số với tên gợi ý\n",
        "parser.add_argument('--data_root', type=str, help='Description of arg1')\n",
        "parser.add_argument('--out_puts', type=str, help='Description of arg2')\n",
        "\n",
        "# Parse các đối số từ dòng lệnh\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "cudaDevice = ''\n",
        "\n",
        "if len(cudaDevice) < 1:\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print('[*] GPU Device selected as default execution device.')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print('[X] WARN: No GPU Devices found on the system! Using the CPU. '\n",
        "              'Execution maybe slow!')\n",
        "else:\n",
        "    device = torch.device('cuda:%s' % cudaDevice)\n",
        "    print('[*] GPU Device %s selected as default execution device.' %\n",
        "          cudaDevice)\n",
        "\n",
        "#visuals = 'test_outputs/'\n",
        "visuals = args.out_puts\n",
        "\n",
        "os.makedirs(visuals, exist_ok=True)\n",
        "\n",
        "modelSaveLoc = 'model/real_world_model.t7'\n",
        "\n",
        "#data_root = 'test'\n",
        "query_fmt = 'jpg'\n",
        "\n",
        "# Truy cập các đối số trong mã Python\n",
        "data_root = args.data_root\n",
        "\n",
        "batch_size = 1\n",
        "nthreads = 4\n",
        "if batch_size < nthreads:\n",
        "    nthreads = batch_size\n",
        "\n",
        "done = u'\\u2713'\n",
        "\n",
        "print('[I] STATUS: Create utils instances...', end='')\n",
        "support = mor_utils(device)\n",
        "print(done)\n",
        "\n",
        "print('[I] STATUS: Load Network and transfer to device...', end='')\n",
        "net = DecScaleClampedIllumEdgeGuidedNetworkBatchNorm().to(device)\n",
        "net, _, _ = support.loadModels(net, modelSaveLoc)\n",
        "net.to(device)\n",
        "print(done)\n",
        "\n",
        "def readFile(name):\n",
        "    im = imageio.imread(name)\n",
        "    if len(im.shape) == 2:  # Kiểm tra xem ảnh có 2 chiều không (ảnh xám)\n",
        "      im = np.stack((im,) * 3, axis=-1)  # Lặp lại giá trị pixel 3 lần\n",
        "    rgb = im.astype(np.float32)\n",
        "    rgb[np.isnan(rgb)] = 0\n",
        "    rgb = cv2.resize(rgb, (256, 256))\n",
        "    rgb = rgb / 255\n",
        "\n",
        "    rgb = rgb.transpose((2, 0, 1))\n",
        "    return rgb\n",
        "\n",
        "def Eval(net):\n",
        "    net.eval()\n",
        "    #print(os.listdir(data_root))\n",
        "    #files = glob.glob(data_root + '*.%s' % query_fmt)\n",
        "    files = os.listdir(data_root)\n",
        "    print('Found %d files at query location' % len(files))\n",
        "    #files = ['/content/PIE-Net/test/000609798.jpg']\n",
        "    i = 0\n",
        "    for data in tqdm(files):\n",
        "        if i<0:\n",
        "          break\n",
        "        i+=1\n",
        "        #data = data.split('/')[-1]\n",
        "        \n",
        "        img = readFile(os.path.join(data_root,data))\n",
        "        rgb = Variable(torch.from_numpy(img).float()).to(device)\n",
        "        rgb = rgb.unsqueeze(0)\n",
        "        [b, c, w, h] = rgb.shape\n",
        "\n",
        "        net_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            pred = net(rgb)\n",
        "\n",
        "        net_timed = time.time() - net_time\n",
        "\n",
        "        for j in range(b):\n",
        "            pred_dict = {'reflectance': pred['reflectance'][j, :, :, :],\n",
        "                         #'img': rgb[j, :, :, :],\n",
        "                         'shading': pred['shading'][j, :, :, :],\n",
        "                        }\n",
        "            support.dumpOutputs3(visuals, pred_dict, filename=data, Train=False)\n",
        "\n",
        "\n",
        "print('[*] Beginning Testing:')\n",
        "print('\\tVisuals Dumped at: ', visuals)\n",
        "\n",
        "Eval(net)\n"
      ],
      "metadata": {
        "id": "-8b8dy_37lTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit Ultils  \n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class mor_utils:\n",
        "\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "\n",
        "    def printTensorList(self, data):\n",
        "        if isinstance(data, dict):\n",
        "            print('Dictionary Containing: ')\n",
        "            print('{')\n",
        "            for key, tensor in data.items():\n",
        "                print('\\t', key, end='')\n",
        "                print(' with Tensor of Size: ', tensor.size())\n",
        "            print('}')\n",
        "        else:\n",
        "            print('List Containing: ')\n",
        "            print('[')\n",
        "            for tensor in data:\n",
        "                print('\\tTensor of Size: ', tensor.size())\n",
        "            print(']')\n",
        "\n",
        "    def saveModels(self, model, optims, iterations, path):\n",
        "        if isinstance(model, nn.DataParallel):\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.module.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        else:\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    def loadModels(self, model, path, optims=None, Test=True):\n",
        "        checkpoint = torch.load(path)\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "        if not Test:\n",
        "            optims.load_state_dict(checkpoint['optimizer'])\n",
        "        return model, optims, checkpoint['iters']\n",
        "\n",
        "    def dumpOutputs(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            imageio.imwrite((vis + '/%s_pred_alb.png') % filename, pred_a)\n",
        "            imageio.imwrite((vis + '/%s_pred_shd.png') % filename, pred_s)\n",
        "\n",
        "    def dumpOutputs3(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            for k, ele in preds.items():\n",
        "                pred = ele.cpu().detach().clone().numpy()\n",
        "                pred[pred < 0] = 0\n",
        "                pred = (pred / pred.max()) * 255\n",
        "                pred = pred.transpose((1, 2, 0))\n",
        "                pred = pred.astype(np.uint8)\n",
        "                #print('shape is === ', pred.shape)\n",
        "                #pred = Image.fromarray(pred)\n",
        "                #pred = pred.convert(\"RGB\")\n",
        "                if (pred.shape==(256,256,1)):\n",
        "                  #print(pred.shape)\n",
        "                  pred = pred.squeeze()\n",
        "                  #print(pred.shape)\n",
        "                imageio.imwrite((vis + '/%s_%s.jpg') % (filename, k), pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gyJJIOnn8AHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZs5GdsK76pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import imageio\n",
        "import numpy as np\n",
        "im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n",
        "print(im.shape)\n",
        "if len(im.shape) == 2:  # Kiểm tra xem ảnh có 2 chiều không (ảnh xám)\n",
        "    im = np.stack((im,) * 3, axis=-1)  # Lặp lại giá trị pixel 3 lần\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxE220w-z0GR",
        "outputId": "9b0a5c05-bcbd-46a9-a2f8-92c4e96bc095"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-d8a6d4c270f7>:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(im.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ko0yLOFz-AG",
        "outputId": "6cc20db0-1827-46ac-a94d-141da22aaa74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n"
          ]
        }
      ]
    }
  ]
}