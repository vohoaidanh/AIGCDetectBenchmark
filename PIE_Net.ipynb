{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1awHTdkYS3eyzH1AzO9BLfCdsHFpjdas7",
      "authorship_tag": "ABX9TyPy9XRmTq9yPeyhiadOy+Pz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/AIGCDetectBenchmark/blob/main/PIE_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition\n",
        "https://github.com/Morpheus3000/PIE-Net/tree/main?tab=readme-ov-file  \n"
      ],
      "metadata": {
        "id": "OTiypmgfnX4q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkfgrKKnPzo",
        "outputId": "e2b03e4a-f68a-4999-b886-41f20af9cec8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-28 02:52:00--  https://uvaauas.figshare.com/ndownloader/files/35467808\n",
            "Resolving uvaauas.figshare.com (uvaauas.figshare.com)... 34.249.22.33, 52.30.40.166, 2a05:d018:1f4:d003:8d1a:b96f:3b54:baed, ...\n",
            "Connecting to uvaauas.figshare.com (uvaauas.figshare.com)|34.249.22.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T025201Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=d7131cba1b382a1ebd49d3c94e629adaa32445f983bda95fa5aec954eadb348b [following]\n",
            "--2024-02-28 02:52:01--  https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T025201Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=d7131cba1b382a1ebd49d3c94e629adaa32445f983bda95fa5aec954eadb348b\n",
            "Resolving s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)... 163.172.208.8, 2001:bc8:1401::8\n",
            "Connecting to s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)|163.172.208.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2449443791 (2.3G) [application/octet-stream]\n",
            "Saving to: ‘35467808’\n",
            "\n",
            "35467808            100%[===================>]   2.28G  27.1MB/s    in 97s     \n",
            "\n",
            "2024-02-28 02:53:38 (24.2 MB/s) - ‘35467808’ saved [2449443791/2449443791]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://uvaauas.figshare.com/ndownloader/files/35467808"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Morpheus3000/PIE-Net.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3H_nL0hLoYyH",
        "outputId": "8d3e311e-acda-462f-d8ee-94afe3c394e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PIE-Net'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 61 (delta 13), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Receiving objects: 100% (61/61), 30.81 MiB | 21.71 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PIE-Net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz7QKPIhpBHh",
        "outputId": "d50c2245-dd8d-4be6-c7eb-89faff812402"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PIE-Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Eval.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtC6YGg6pEAd",
        "outputId": "c19c5463-884b-415e-d5a8-02e25514965f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[X] WARN: No GPU Devices found on the system! Using the CPU. Execution maybe slow!\n",
            "[I] STATUS: Create utils instances...✓\n",
            "[I] STATUS: Load Network and transfer to device...✓\n",
            "[*] Beginning Testing:\n",
            "\tVisuals Dumped at:  test_outputs/\n",
            "Found 9 files at query location\n",
            "  0% 0/1 [00:00<?, ?it/s]/content/PIE-Net/Eval.py:60: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread(name)\n",
            "shape is ===  (256, 256, 3)\n",
            "shape is ===  (256, 256, 3)\n",
            "shape is ===  (256, 256, 1)\n",
            "(256, 256, 1)\n",
            "(256, 256)\n",
            "100% 1/1 [00:24<00:00, 24.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/PIE-Net/model/real_world_model.t7 /content/drive/MyDrive/WEIGHTS/PIE-Net"
      ],
      "metadata": {
        "id": "WkuTBfJ3_VnP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit rpogram\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import imageio\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from Network import DecScaleClampedIllumEdgeGuidedNetworkBatchNorm\n",
        "from Utils import mor_utils\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "cudaDevice = ''\n",
        "\n",
        "if len(cudaDevice) < 1:\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print('[*] GPU Device selected as default execution device.')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print('[X] WARN: No GPU Devices found on the system! Using the CPU. '\n",
        "              'Execution maybe slow!')\n",
        "else:\n",
        "    device = torch.device('cuda:%s' % cudaDevice)\n",
        "    print('[*] GPU Device %s selected as default execution device.' %\n",
        "          cudaDevice)\n",
        "\n",
        "visuals = 'test_outputs/'\n",
        "os.makedirs(visuals, exist_ok=True)\n",
        "\n",
        "modelSaveLoc = 'model/real_world_model.t7'\n",
        "\n",
        "data_root = 'test'\n",
        "query_fmt = 'jpg'\n",
        "\n",
        "batch_size = 1\n",
        "nthreads = 4\n",
        "if batch_size < nthreads:\n",
        "    nthreads = batch_size\n",
        "\n",
        "done = u'\\u2713'\n",
        "\n",
        "print('[I] STATUS: Create utils instances...', end='')\n",
        "support = mor_utils(device)\n",
        "print(done)\n",
        "\n",
        "print('[I] STATUS: Load Network and transfer to device...', end='')\n",
        "net = DecScaleClampedIllumEdgeGuidedNetworkBatchNorm().to(device)\n",
        "net, _, _ = support.loadModels(net, modelSaveLoc)\n",
        "net.to(device)\n",
        "print(done)\n",
        "\n",
        "def readFile(name):\n",
        "    im = imageio.imread(name)\n",
        "    rgb = im.astype(np.float32)\n",
        "    rgb[np.isnan(rgb)] = 0\n",
        "    rgb = cv2.resize(rgb, (256, 256))\n",
        "    rgb = rgb / 255\n",
        "\n",
        "    rgb = rgb.transpose((2, 0, 1))\n",
        "    return rgb\n",
        "\n",
        "def Eval(net):\n",
        "    net.eval()\n",
        "    #print(os.listdir(data_root))\n",
        "    #files = glob.glob(data_root + '*.%s' % query_fmt)\n",
        "    files = os.listdir(data_root)\n",
        "    print('Found %d files at query location' % len(files))\n",
        "    files = ['/content/PIE-Net/test/000609798.jpg']\n",
        "    for data in tqdm(files):\n",
        "\n",
        "        data = data.split('/')[-1]\n",
        "        \n",
        "        img = readFile(os.path.join(data_root,data))\n",
        "        rgb = Variable(torch.from_numpy(img).float()).to(device)\n",
        "        rgb = rgb.unsqueeze(0)\n",
        "        [b, c, w, h] = rgb.shape\n",
        "\n",
        "        net_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            pred = net(rgb)\n",
        "\n",
        "        net_timed = time.time() - net_time\n",
        "\n",
        "        for j in range(b):\n",
        "            pred_dict = {'pred_alb': pred['reflectance'][j, :, :, :],\n",
        "                         'img': rgb[j, :, :, :],\n",
        "                         'pred_shd': pred['shading'][j, :, :, :],\n",
        "                        }\n",
        "            support.dumpOutputs3(visuals, pred_dict, filename=data, Train=False)\n",
        "\n",
        "\n",
        "print('[*] Beginning Testing:')\n",
        "print('\\tVisuals Dumped at: ', visuals)\n",
        "\n",
        "Eval(net)\n"
      ],
      "metadata": {
        "id": "-8b8dy_37lTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit Ultils  \n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class mor_utils:\n",
        "\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "\n",
        "    def printTensorList(self, data):\n",
        "        if isinstance(data, dict):\n",
        "            print('Dictionary Containing: ')\n",
        "            print('{')\n",
        "            for key, tensor in data.items():\n",
        "                print('\\t', key, end='')\n",
        "                print(' with Tensor of Size: ', tensor.size())\n",
        "            print('}')\n",
        "        else:\n",
        "            print('List Containing: ')\n",
        "            print('[')\n",
        "            for tensor in data:\n",
        "                print('\\tTensor of Size: ', tensor.size())\n",
        "            print(']')\n",
        "\n",
        "    def saveModels(self, model, optims, iterations, path):\n",
        "        if isinstance(model, nn.DataParallel):\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.module.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        else:\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    def loadModels(self, model, path, optims=None, Test=True):\n",
        "        checkpoint = torch.load(path, map_location='cpu')\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "        if not Test:\n",
        "            optims.load_state_dict(checkpoint['optimizer'])\n",
        "        return model, optims, checkpoint['iters']\n",
        "\n",
        "    def dumpOutputs(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            imageio.imwrite((vis + '/%s_pred_alb.png') % filename, pred_a)\n",
        "            imageio.imwrite((vis + '/%s_pred_shd.png') % filename, pred_s)\n",
        "\n",
        "    def dumpOutputs3(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            for k, ele in preds.items():\n",
        "                pred = ele.cpu().detach().clone().numpy()\n",
        "                pred[pred < 0] = 0\n",
        "                pred = (pred / pred.max()) * 255\n",
        "                pred = pred.transpose((1, 2, 0))\n",
        "                pred = pred.astype(np.uint8)\n",
        "                print('shape is === ', pred.shape)\n",
        "                #pred = Image.fromarray(pred)\n",
        "                #pred = pred.convert(\"RGB\")\n",
        "                if (pred.shape==(256,256,1)):\n",
        "                  print(pred.shape)\n",
        "                  pred = pred.squeeze()\n",
        "                  print(pred.shape)\n",
        "                imageio.imwrite((vis + '/%s_%s.jpg') % (filename, k), pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gyJJIOnn8AHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZs5GdsK76pc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}