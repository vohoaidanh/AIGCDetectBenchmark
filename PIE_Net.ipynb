{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gyJJIOnn8AHJ"
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vohoaidanh/AIGCDetectBenchmark/blob/main/PIE_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition\n",
        "https://github.com/Morpheus3000/PIE-Net/tree/main?tab=readme-ov-file  \n"
      ],
      "metadata": {
        "id": "OTiypmgfnX4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQcptCr5laHp",
        "outputId": "8ad39ddc-60c2-4212-d4ed-79c9a604d888"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Morpheus3000/PIE-Net.git"
      ],
      "metadata": {
        "id": "5ZPlyYRzAVAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5323711d-2947-4352-95e1-8e49f3faafc6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PIE-Net'...\n",
            "remote: Enumerating objects: 61, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (39/39), done.\u001b[K\n",
            "remote: Total 61 (delta 13), reused 0 (delta 0), pack-reused 22\u001b[K\n",
            "Receiving objects: 100% (61/61), 30.81 MiB | 24.98 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VfkfgrKKnPzo",
        "outputId": "0fac45a7-2622-4477-af28-f4803593aead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-28 07:21:14--  https://uvaauas.figshare.com/ndownloader/files/35467808\n",
            "Resolving uvaauas.figshare.com (uvaauas.figshare.com)... 34.249.22.33, 52.30.40.166, 2a05:d018:1f4:d000:b899:c458:6346:b0d3, ...\n",
            "Connecting to uvaauas.figshare.com (uvaauas.figshare.com)|34.249.22.33|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T072115Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=9b682fd1ab335114d91a87f748105039ff0f0ff765d5ab0c1d8d12416f1b46ab [following]\n",
            "--2024-02-28 07:21:15--  https://s3.nl-ams.scw.cloud/pstorage-amster-45168546/35467808/real_world_model.t7?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=SCW90ENHXE6G7FVJV73C/20240228/nl-ams/s3/aws4_request&X-Amz-Date=20240228T072115Z&X-Amz-Expires=10&X-Amz-SignedHeaders=host&X-Amz-Signature=9b682fd1ab335114d91a87f748105039ff0f0ff765d5ab0c1d8d12416f1b46ab\n",
            "Resolving s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)... 163.172.208.8, 2001:bc8:1401::8\n",
            "Connecting to s3.nl-ams.scw.cloud (s3.nl-ams.scw.cloud)|163.172.208.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2449443791 (2.3G) [application/octet-stream]\n",
            "Saving to: ‘35467808’\n",
            "\n",
            "35467808            100%[===================>]   2.28G  29.7MB/s    in 81s     \n",
            "\n",
            "2024-02-28 07:22:36 (29.0 MB/s) - ‘35467808’ saved [2449443791/2449443791]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://uvaauas.figshare.com/ndownloader/files/35467808\n",
        "#!cp /content/drive/MyDrive/WEIGHTS/PIE-Net/real_world_model.t7 /content/PIE-Net/model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd PIE-Net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kz7QKPIhpBHh",
        "outputId": "0c5a73d1-fa06-4720-cc57-4e544de463cf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PIE-Net\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python Eval.py --data_root real_gen_dataset/train/0_real --out_puts data/real_gen_dataset/train/0_real"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtC6YGg6pEAd",
        "outputId": "c6cdadce-e0b0-470e-86b5-e788a8ff85ef"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] GPU Device selected as default execution device.\n",
            "[I] STATUS: Create utils instances...✓\n",
            "[I] STATUS: Load Network and transfer to device...✓\n",
            "[*] Beginning Testing:\n",
            "\tVisuals Dumped at:  data/real_gen_dataset/train/0_real\n",
            "Found 1790 files at query location\n",
            "  0% 0/1790 [00:00<?, ?it/s]/content/PIE-Net/Eval.py:71: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread(name)\n",
            "100% 1790/1790 [09:45<00:00,  3.06it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(len(os.listdir('/content/PIE-Net/test')))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOO-nyUumaXh",
        "outputId": "f16a6dc6-1b1d-44c7-d0fb-42743e6c918c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tạo thư mục mới\n",
        "\"\"\"\n",
        "!mkdir -p /content/PIE-Net/data/real_gen_dataset/test/0_real/\n",
        "!mkdir -p /content/PIE-Net/data/real_gen_dataset/test/1_fake/\n",
        "!mkdir -p /content/PIE-Net/data/real_gen_dataset/train/0_real/\n",
        "!mkdir -p /content/PIE-Net/data/real_gen_dataset/train/1_fake/\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "o9r68U_DsCl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp /content/PIE-Net/model/real_world_model.t7 /content/drive/MyDrive/WEIGHTS/PIE-Net\n",
        "#!cp /content/drive/MyDrive/DATASETS/real_gen_dataset.zip /content/"
      ],
      "metadata": {
        "id": "WkuTBfJ3_VnP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!unzip /content/real_gen_dataset.zip -d /content/PIE-Net/\n",
        "#!zip -r PIE_Net_real_gen_dataset.zip /content/PIE-Net/data/real_gen_dataset\n",
        "!cp PIE_Net_real_gen_dataset.zip /content/drive/MyDrive/\n"
      ],
      "metadata": {
        "id": "wN8JoNYrrdL0"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit rpogram\n",
        "\n",
        "import os\n",
        "import time\n",
        "\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import imageio\n",
        "import glob\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from Network import DecScaleClampedIllumEdgeGuidedNetworkBatchNorm\n",
        "from Utils import mor_utils\n",
        "\n",
        "\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "cudaDevice = ''\n",
        "\n",
        "if len(cudaDevice) < 1:\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print('[*] GPU Device selected as default execution device.')\n",
        "    else:\n",
        "        device = torch.device('cpu')\n",
        "        print('[X] WARN: No GPU Devices found on the system! Using the CPU. '\n",
        "              'Execution maybe slow!')\n",
        "else:\n",
        "    device = torch.device('cuda:%s' % cudaDevice)\n",
        "    print('[*] GPU Device %s selected as default execution device.' %\n",
        "          cudaDevice)\n",
        "\n",
        "visuals = 'test_outputs/'\n",
        "os.makedirs(visuals, exist_ok=True)\n",
        "\n",
        "modelSaveLoc = 'model/real_world_model.t7'\n",
        "\n",
        "data_root = 'test'\n",
        "query_fmt = 'jpg'\n",
        "\n",
        "batch_size = 1\n",
        "nthreads = 4\n",
        "if batch_size < nthreads:\n",
        "    nthreads = batch_size\n",
        "\n",
        "done = u'\\u2713'\n",
        "\n",
        "print('[I] STATUS: Create utils instances...', end='')\n",
        "support = mor_utils(device)\n",
        "print(done)\n",
        "\n",
        "print('[I] STATUS: Load Network and transfer to device...', end='')\n",
        "net = DecScaleClampedIllumEdgeGuidedNetworkBatchNorm().to(device)\n",
        "net, _, _ = support.loadModels(net, modelSaveLoc)\n",
        "net.to(device)\n",
        "print(done)\n",
        "\n",
        "def readFile(name):\n",
        "    im = imageio.imread(name)\n",
        "    rgb = im.astype(np.float32)\n",
        "    rgb[np.isnan(rgb)] = 0\n",
        "    rgb = cv2.resize(rgb, (256, 256))\n",
        "    rgb = rgb / 255\n",
        "\n",
        "    rgb = rgb.transpose((2, 0, 1))\n",
        "    return rgb\n",
        "\n",
        "def Eval(net):\n",
        "    net.eval()\n",
        "    #print(os.listdir(data_root))\n",
        "    #files = glob.glob(data_root + '*.%s' % query_fmt)\n",
        "    files = os.listdir(data_root)\n",
        "    print('Found %d files at query location' % len(files))\n",
        "    files = ['/content/PIE-Net/test/000609798.jpg']\n",
        "    for data in tqdm(files):\n",
        "\n",
        "        data = data.split('/')[-1]\n",
        "        \n",
        "        img = readFile(os.path.join(data_root,data))\n",
        "        rgb = Variable(torch.from_numpy(img).float()).to(device)\n",
        "        rgb = rgb.unsqueeze(0)\n",
        "        [b, c, w, h] = rgb.shape\n",
        "\n",
        "        net_time = time.time()\n",
        "        with torch.no_grad():\n",
        "            pred = net(rgb)\n",
        "\n",
        "        net_timed = time.time() - net_time\n",
        "\n",
        "        for j in range(b):\n",
        "            pred_dict = {'pred_alb': pred['reflectance'][j, :, :, :],\n",
        "                         'img': rgb[j, :, :, :],\n",
        "                         'pred_shd': pred['shading'][j, :, :, :],\n",
        "                        }\n",
        "            support.dumpOutputs3(visuals, pred_dict, filename=data, Train=False)\n",
        "\n",
        "\n",
        "print('[*] Beginning Testing:')\n",
        "print('\\tVisuals Dumped at: ', visuals)\n",
        "\n",
        "Eval(net)\n"
      ],
      "metadata": {
        "id": "-8b8dy_37lTb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Edit Ultils  \n",
        "\n",
        "import os\n",
        "import imageio\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "class mor_utils:\n",
        "\n",
        "    def __init__(self, device):\n",
        "        self.device = device\n",
        "\n",
        "    def printTensorList(self, data):\n",
        "        if isinstance(data, dict):\n",
        "            print('Dictionary Containing: ')\n",
        "            print('{')\n",
        "            for key, tensor in data.items():\n",
        "                print('\\t', key, end='')\n",
        "                print(' with Tensor of Size: ', tensor.size())\n",
        "            print('}')\n",
        "        else:\n",
        "            print('List Containing: ')\n",
        "            print('[')\n",
        "            for tensor in data:\n",
        "                print('\\tTensor of Size: ', tensor.size())\n",
        "            print(']')\n",
        "\n",
        "    def saveModels(self, model, optims, iterations, path):\n",
        "        if isinstance(model, nn.DataParallel):\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.module.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        else:\n",
        "            checkpoint = {\n",
        "                'iters': iterations,\n",
        "                'model': model.state_dict(),\n",
        "                'optimizer': optims.state_dict()\n",
        "            }\n",
        "        torch.save(checkpoint, path)\n",
        "\n",
        "    def loadModels(self, model, path, optims=None, Test=True):\n",
        "        checkpoint = torch.load(path, map_location='cpu')\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "        if not Test:\n",
        "            optims.load_state_dict(checkpoint['optimizer'])\n",
        "        return model, optims, checkpoint['iters']\n",
        "\n",
        "    def dumpOutputs(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            imageio.imwrite((vis + '/%s_pred_alb.png') % filename, pred_a)\n",
        "            imageio.imwrite((vis + '/%s_pred_shd.png') % filename, pred_s)\n",
        "\n",
        "    def dumpOutputs3(self, vis, preds, gts=None, num=13, iteration=0,\n",
        "                    filename='Out_%d_%d.png', Train=True):\n",
        "\n",
        "        if Train:\n",
        "            \"\"\"Function to Collage the predictions with the outputs. Expects a single\n",
        "            set and not batches.\"\"\"\n",
        "\n",
        "            pred_a = preds[0].cpu().detach().clone().numpy()\n",
        "            pred_a = (pred_a / pred_a.max()) * 255\n",
        "            pred_a = pred_a.transpose((1, 2, 0))\n",
        "            pred_a = pred_a.astype(np.uint8)\n",
        "\n",
        "            pred_s = preds[1].cpu().detach().clone().numpy()\n",
        "            pred_s[pred_s < 0] = 0\n",
        "            pred_s = (pred_s / pred_s.max()) * 255\n",
        "            pred_s = pred_s.transpose((1, 2, 0))\n",
        "            pred_s = pred_s.astype(np.uint8)\n",
        "\n",
        "            img = gts[0].cpu().detach().clone().numpy() * 255\n",
        "            img = img.astype(np.uint8)\n",
        "            img = img.transpose(1, 2, 0)\n",
        "\n",
        "            alb = gts[1].cpu().detach().clone().numpy() * 255\n",
        "            alb = alb.astype(np.uint8)\n",
        "            alb = alb.transpose(1, 2, 0)\n",
        "\n",
        "            shd = gts[2].cpu().detach().clone().numpy() * 255\n",
        "            shd = shd.astype(np.uint8)\n",
        "            shd = shd.transpose(1, 2, 0)\n",
        "\n",
        "            norm = preds[2].cpu().detach().clone().numpy() * 255\n",
        "            norm[norm < 0] = 0\n",
        "            norm = (norm / norm.max()) * 255\n",
        "            norm = norm.astype(np.uint8)\n",
        "            norm = norm.transpose(1, 2, 0)\n",
        "\n",
        "            row1 = np.concatenate((img, alb, shd), axis=1)\n",
        "            row2 = np.concatenate((norm, pred_a, pred_s), axis=1)\n",
        "            full = np.concatenate((row1, row2), axis=0)\n",
        "\n",
        "            imageio.imwrite(vis + '/' + filename % (num, iteration), full)\n",
        "\n",
        "        else:\n",
        "            for k, ele in preds.items():\n",
        "                pred = ele.cpu().detach().clone().numpy()\n",
        "                pred[pred < 0] = 0\n",
        "                pred = (pred / pred.max()) * 255\n",
        "                pred = pred.transpose((1, 2, 0))\n",
        "                pred = pred.astype(np.uint8)\n",
        "                print('shape is === ', pred.shape)\n",
        "                #pred = Image.fromarray(pred)\n",
        "                #pred = pred.convert(\"RGB\")\n",
        "                if (pred.shape==(256,256,1)):\n",
        "                  print(pred.shape)\n",
        "                  pred = pred.squeeze()\n",
        "                  print(pred.shape)\n",
        "                imageio.imwrite((vis + '/%s_%s.jpg') % (filename, k), pred)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gyJJIOnn8AHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UZs5GdsK76pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "import imageio\n",
        "import numpy as np\n",
        "im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n",
        "print(im.shape)\n",
        "if len(im.shape) == 2:  # Kiểm tra xem ảnh có 2 chiều không (ảnh xám)\n",
        "    im = np.stack((im,) * 3, axis=-1)  # Lặp lại giá trị pixel 3 lần\n",
        "    \"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxE220w-z0GR",
        "outputId": "9b0a5c05-bcbd-46a9-a2f8-92c4e96bc095"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-d8a6d4c270f7>:3: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
            "  im = imageio.imread('/content/PIE-Net/data/real_gen_dataset/train/0_real/000609232.jpg_shading.jpg')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#print(im.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ko0yLOFz-AG",
        "outputId": "6cc20db0-1827-46ac-a94d-141da22aaa74"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(256, 256, 3)\n"
          ]
        }
      ]
    }
  ]
}